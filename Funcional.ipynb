{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcef3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import time\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import youtube_dl\n",
    "import librosa\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from __future__ import unicode_literals\n",
    "from os import path, listdir \n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903c9e4",
   "metadata": {},
   "source": [
    "# Song divided every 5s concatenate with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e1cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def music_path(path):\n",
    "    directories = [i for i in listdir(path) if not i.startswith(\".\")]\n",
    "    for genre in directories:\n",
    "        for song in listdir(f\"{path}/{genre}\"):\n",
    "            if not song.startswith(\".\"):\n",
    "                yield f\"{path}/{genre}/{song}\", genre\n",
    "                \n",
    "def add_features(song, sr):\n",
    "    res = []\n",
    "    for part in song:\n",
    "        union = part\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(part, sr)\n",
    "        print(mfcc.shape)\n",
    "        for element in mfcc:\n",
    "            union = np.concatenate((union, element), axis=None)\n",
    "        \n",
    "        chroma_stft = librosa.feature.chroma_stft(part, sr)\n",
    "        for element in chroma_stft:\n",
    "            union = np.concatenate((union, element), axis=None)\n",
    "        \n",
    "        spectral_centroid = librosa.feature.spectral_centroid(part, sr)\n",
    "        union = np.concatenate((union, spectral_centroid), axis=None)\n",
    "        \n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(part, sr)\n",
    "        union = np.concatenate((union, zero_crossing_rate), axis=None)\n",
    "        res.append(union)\n",
    "    return np.array(res)\n",
    "        \n",
    "def split_song(song, sr, seconds = 5):\n",
    "    res = []\n",
    "    for i in range(1, len(song)//(sr*seconds)):\n",
    "        res.append(song[(i-1)*sr*seconds : i*sr*seconds])\n",
    "    return np.array(res)\n",
    "                \n",
    "def load_song(path):\n",
    "    x , sr = librosa.load(path, mono=True, sr=44100)\n",
    "    splited_song = split_song(x,sr,5)\n",
    "    for song in add_features(splited_song, sr):\n",
    "        yield song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490bc767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def songs_array(default = 'music'):\n",
    "    data = []\n",
    "    y = []\n",
    "    for song_path, genre in music_path(default): \n",
    "        for part_song in load_song(song_path):\n",
    "            data.append(part_song)\n",
    "            y.append(genre)\n",
    "    return np.array(data), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce68cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x,y = songs_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a68961",
   "metadata": {},
   "source": [
    "# Song divided every 5s, only mean features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(song, sr):\n",
    "    data = []\n",
    "    \n",
    "    for part in song:\n",
    "        #s_part = np.array(part)\n",
    "        res = []\n",
    "        union = 0\n",
    "        mfcc = librosa.feature.mfcc(part, sr)\n",
    "        for element in mfcc:\n",
    "            #union = sum(element)\n",
    "            res.append((sum(element)/mfcc.shape[1]))\n",
    "        #res.append((union/mfcc.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        rms = librosa.feature.rms(part, sr)\n",
    "        union = sum(rms[0])\n",
    "        res.append((union/rms.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        chroma_stft = librosa.feature.chroma_stft(part, sr)\n",
    "        for element in chroma_stft:\n",
    "            #union = sum(element)\n",
    "            res.append((sum(element)/chroma_stft.shape[1]))\n",
    "        #res.append((union/chroma_stft.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(part, sr)\n",
    "        union = sum(spectral_bandwidth[0])\n",
    "        res.append((union/spectral_bandwidth.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(part, sr)\n",
    "        for element in spectral_contrast:\n",
    "            #union = sum(element)\n",
    "            res.append((sum(element)/spectral_contrast.shape[1]))\n",
    "        #res.append((union/spectral_contrast.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        spectral_flatness = librosa.feature.spectral_flatness(part)\n",
    "        union = sum(spectral_flatness[0])\n",
    "        res.append((union/spectral_flatness.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(part, sr)\n",
    "        union = sum(spectral_rolloff[0])\n",
    "        res.append((union/spectral_rolloff.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(part, sr)\n",
    "        union = sum(spectral_centroid[0])\n",
    "        res.append((union/spectral_centroid.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        tonnetz = librosa.feature.tonnetz(part, sr)\n",
    "        for element in tonnetz:\n",
    "            #union = sum(element)\n",
    "            res.append((sum(element)/tonnetz.shape[1]))\n",
    "        #res.append((union/tonnetz.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(part, sr)\n",
    "        union = sum(zero_crossing_rate[0])\n",
    "        \n",
    "        res.append((union/zero_crossing_rate.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        tempogram = librosa.feature.tempogram(part, sr)\n",
    "        for element in tempogram:\n",
    "            #union = sum(element)\n",
    "            res.append((sum(element)/tempogram.shape[1]))\n",
    "        #res.append((union/tempogram.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        fourier_tempogram = librosa.feature.fourier_tempogram(part, sr)\n",
    "        for element in fourier_tempogram:\n",
    "            #union = abs(sum(element))\n",
    "            res.append((sum(element).real/fourier_tempogram.shape[1]))\n",
    "        #res.append((union/fourier_tempogram.shape[1]))\n",
    "        \n",
    "        tempo = librosa.beat.tempo(part, sr)\n",
    "        res.append(tempo[0])\n",
    "        \n",
    "        beat_track = librosa.beat.beat_track(part, sr)\n",
    "        res.append(beat_track[0])\n",
    "        \n",
    "        union = 0\n",
    "        plp = librosa.beat.plp(part, sr)\n",
    "        for element in plp:\n",
    "            union += element\n",
    "        res.append((union/plp.shape[0]))\n",
    "        \n",
    "        data.append(res)\n",
    "\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c5e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x,y = songs_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef086a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9b8f3",
   "metadata": {},
   "source": [
    "# Song divided every 5s, only features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_full_song(song, sr):\n",
    "    res = []\n",
    "    \n",
    "    union = song\n",
    "    mfcc = librosa.feature.mfcc(song, sr)\n",
    "    for element in mfcc:\n",
    "        union = np.concatenate((union, element), axis=None)\n",
    "    res.append(union)\n",
    "\n",
    "    union = song\n",
    "    chroma_stft = librosa.feature.chroma_stft(song, sr)\n",
    "    for element in chroma_stft:\n",
    "        union = np.concatenate((union, element), axis=None)\n",
    "    res.append(union)\n",
    "\n",
    "    union = song\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(song, sr)\n",
    "    union = np.concatenate((union, spectral_centroid), axis=None)\n",
    "    res.append(union)\n",
    "\n",
    "    union = song\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(song, sr)\n",
    "    union = np.concatenate((union, zero_crossing_rate), axis=None)\n",
    "    res.append(union)\n",
    "    \n",
    "    return np.array(res)\n",
    "\n",
    "def load_full_song(path):\n",
    "    x , sr = librosa.load(path, mono=True, sr=44100)\n",
    "    song_features = add_features_full_song(x, sr)\n",
    "    song = np.array([song_features])\n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c449ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_songs_array(default = 'music'):\n",
    "    data = []\n",
    "    y = []\n",
    "    for song_path, genre in music_path(default): \n",
    "        for part_song in load_full_song(song_path):\n",
    "            data.append(part_song)\n",
    "            y.append(genre)\n",
    "    return np.array(data), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ed6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x,y = full_songs_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b609cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f95053",
   "metadata": {},
   "source": [
    "# Image song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c3b45627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def music_path(path):\n",
    "    directories = [i for i in listdir(path) if not i.startswith(\".\")]\n",
    "    for genre in directories:\n",
    "        for song in listdir(f\"{path}/{genre}\"):\n",
    "            if not song.startswith(\".\"):\n",
    "                yield f\"{path}/{genre}/{song}\", genre\n",
    "\n",
    "def img_song(song, path):\n",
    "    stft = librosa.stft(song)\n",
    "    song_db = librosa.amplitude_to_db(stft)\n",
    "    librosa.display.specshow(song_db)\n",
    "    plt.savefig(f'{path}.png')\n",
    "    plt.close()\n",
    "    \n",
    "def create_image(default = 'music'):\n",
    "    data = []\n",
    "    y = []\n",
    "    for song_path, genre in music_path(default):\n",
    "        x , sr = librosa.load(song_path, mono=True, sr=44100)\n",
    "        tree_dir = song_path.split(\"/\")\n",
    "        img_song(x, f\"music_image/{genre}/{tree_dir[-1].replace('.wav','')}\")\n",
    "        #data.append(part_song)\n",
    "        #y.append(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1a7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7debd7d0",
   "metadata": {},
   "source": [
    "## Leemos las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3b42caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4213ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img, (img_size, img_size))\n",
    "    return img_resized\n",
    "\n",
    "def img_path(path):\n",
    "    directories = [i for i in listdir(path) if not i.startswith(\".\")]\n",
    "    for genre in directories:\n",
    "        for song_img in listdir(f\"{path}/{genre}\"):\n",
    "            if not song_img.startswith(\".\"):\n",
    "                yield f\"{path}/{genre}/{song_img}\", genre\n",
    "\n",
    "def get_img_data(path = 'music_image'):\n",
    "    data = []\n",
    "    y = []\n",
    "    for img_p, genre in img_path(path): \n",
    "        data.append(read_img(img_p))\n",
    "        y.append(genre)\n",
    "    return np.array(data), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c1a79af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = get_img_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4b2800a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 255, 255, 3)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4828ff",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fe9d1f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre = pd.DataFrame(data=y, columns=[\"Genero\"])\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(genre[[\"Genero\"]])\n",
    "genre_ohe = ohe.transform(genre[[\"Genero\"]]).todense()\n",
    "genre_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8463b824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metal</th>\n",
       "      <th>pop</th>\n",
       "      <th>rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     metal  pop  rock\n",
       "0      1.0  0.0   0.0\n",
       "1      1.0  0.0   0.0\n",
       "2      1.0  0.0   0.0\n",
       "3      1.0  0.0   0.0\n",
       "4      1.0  0.0   0.0\n",
       "..     ...  ...   ...\n",
       "145    0.0  0.0   1.0\n",
       "146    0.0  0.0   1.0\n",
       "147    0.0  0.0   1.0\n",
       "148    0.0  0.0   1.0\n",
       "149    0.0  0.0   1.0\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directories = [i for i in listdir(\"music\") if not i.startswith(\".\")]\n",
    "df_ohe = pd.DataFrame(data=genre_ohe, columns=directories)\n",
    "df_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "67827e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(x, genre_ohe, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "01dcdb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 255, 255, 3), (38, 255, 255, 3), (112, 3), (38, 3))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "06270b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[15., 11., 12.]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.sum(axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b3edfc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4d614d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 255, 255, 3), (38, 255, 255, 3), (112, 3), (38, 3))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train / 255\n",
    "X_val = X_val / 255\n",
    "\n",
    "X_train.reshape(-1, img_size, img_size, 1)\n",
    "X_val.reshape(-1, img_size, img_size, 1)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c5be2fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "073f6f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(128,3,padding='same', activation='relu', input_shape= (img_size, img_size, 3)),\n",
    "    MaxPool2D(),\n",
    "    \n",
    "    Conv2D(256, 3, padding='same', activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    \n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4522d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model = Sequential([\n",
    "    Dense(512, activation=\"relu\", input_shape = (img_size, img_size, 3)),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(3, activation=\"softmax\")\n",
    "])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "71a38c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_81 (Conv2D)           (None, 255, 255, 128)     3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling (None, 127, 127, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 127, 127, 256)     295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 63, 63, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 63, 63, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 31, 31, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 492032)            0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 128)               62980224  \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 64,459,523\n",
      "Trainable params: 64,459,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "73150538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 255, 255, 3), (112, 3))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "49b9b128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 23s 6s/step - loss: 1.9631 - accuracy: 0.3323 - val_loss: 1.1458 - val_accuracy: 0.3158\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 1.1352 - accuracy: 0.3597 - val_loss: 1.1697 - val_accuracy: 0.2895\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.0878 - accuracy: 0.3662 - val_loss: 1.0702 - val_accuracy: 0.6842\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.0822 - accuracy: 0.5074 - val_loss: 1.0541 - val_accuracy: 0.5789\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.0483 - accuracy: 0.4747 - val_loss: 1.0158 - val_accuracy: 0.6053\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.0301 - accuracy: 0.5251 - val_loss: 0.9491 - val_accuracy: 0.8158\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.9568 - accuracy: 0.7475 - val_loss: 0.8567 - val_accuracy: 0.7632\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.8765 - accuracy: 0.6982 - val_loss: 0.7351 - val_accuracy: 0.8947\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.7768 - accuracy: 0.8119 - val_loss: 0.6226 - val_accuracy: 0.8684\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.6979 - accuracy: 0.7128 - val_loss: 0.5473 - val_accuracy: 0.7895\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.6790 - accuracy: 0.7244 - val_loss: 0.4909 - val_accuracy: 0.8421\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.5950 - accuracy: 0.8088 - val_loss: 0.4903 - val_accuracy: 0.8158\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.6208 - accuracy: 0.7442 - val_loss: 0.3872 - val_accuracy: 0.8947\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.5011 - accuracy: 0.7793 - val_loss: 0.3717 - val_accuracy: 0.8684\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.4935 - accuracy: 0.7975 - val_loss: 0.3539 - val_accuracy: 0.8684\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.4490 - accuracy: 0.8048 - val_loss: 0.3271 - val_accuracy: 0.8947\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15289/994753545.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(X_train, \n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m          validation_data=(X_val, \n\u001b[1;32m      4\u001b[0m                           y_val),\n\u001b[1;32m      5\u001b[0m          \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/end/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/end/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/end/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/end/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/end/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/end/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/end/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train,\n",
    "         validation_data=(X_val, \n",
    "                          y_val),\n",
    "         epochs=100,\n",
    "         verbose=1,\n",
    "         batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e7f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('saved_model/mean_features.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf14633",
   "metadata": {},
   "source": [
    "# Predict data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1cb948e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_image('one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d59c1c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = get_img_data('one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "42fc7460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 255, 255, 3)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f0537749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f26e2dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "fe912ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metal -> 0.0\n",
      "pop -> 0.0\n",
      "rock -> 100.0\n"
     ]
    }
   ],
   "source": [
    "directories = [i for i in listdir(\"music\") if not i.startswith(\".\")]\n",
    "res = {}\n",
    "for d in directories:\n",
    "    res[d] = 0\n",
    "\n",
    "for part_song in range(len(y_pred)):\n",
    "    for percent_predict in range(len(y_pred[part_song])):\n",
    "        res[directories[percent_predict]] += y_pred[part_song][percent_predict]\n",
    "\n",
    "for i in res.items():\n",
    "    print(f\"{i[0]} -> {(i[1]/x.shape[0])*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5849b90c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

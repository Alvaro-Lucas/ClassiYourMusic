{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcef3f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: CPU random generator seem to be failing, disable hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import time\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import youtube_dl\n",
    "import librosa\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from __future__ import unicode_literals\n",
    "from os import path, listdir \n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903c9e4",
   "metadata": {},
   "source": [
    "# Song divided every 5s concatenate with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e1cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def music_path(path):\n",
    "    directories = [i for i in listdir(path) if not i.startswith(\".\")]\n",
    "    for genre in directories:\n",
    "        for song in listdir(f\"{path}/{genre}\"):\n",
    "            if not song.startswith(\".\"):\n",
    "                yield f\"{path}/{genre}/{song}\", genre\n",
    "                \n",
    "def add_features(song, sr):\n",
    "    res = []\n",
    "    for part in song:\n",
    "        union = part\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(part, sr)\n",
    "        print(mfcc.shape)\n",
    "        for element in mfcc:\n",
    "            union = np.concatenate((union, element), axis=None)\n",
    "        \n",
    "        chroma_stft = librosa.feature.chroma_stft(part, sr)\n",
    "        for element in chroma_stft:\n",
    "            union = np.concatenate((union, element), axis=None)\n",
    "        \n",
    "        spectral_centroid = librosa.feature.spectral_centroid(part, sr)\n",
    "        union = np.concatenate((union, spectral_centroid), axis=None)\n",
    "        \n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(part, sr)\n",
    "        union = np.concatenate((union, zero_crossing_rate), axis=None)\n",
    "        res.append(union)\n",
    "    return np.array(res)\n",
    "        \n",
    "def split_song(song, sr, seconds = 5):\n",
    "    res = []\n",
    "    for i in range(1, len(song)//(sr*seconds)):\n",
    "        res.append(song[(i-1)*sr*seconds : i*sr*seconds])\n",
    "    return np.array(res)\n",
    "                \n",
    "def load_song(path):\n",
    "    x , sr = librosa.load(path, mono=True, sr=44100)\n",
    "    splited_song = split_song(x,sr,5)\n",
    "    for song in add_features(splited_song, sr):\n",
    "        yield song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490bc767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def songs_array(default = 'music'):\n",
    "    data = []\n",
    "    y = []\n",
    "    for song_path, genre in music_path(default): \n",
    "        for part_song in load_song(song_path):\n",
    "            data.append(part_song)\n",
    "            y.append(genre)\n",
    "    return np.array(data), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce68cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x,y = songs_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a68961",
   "metadata": {},
   "source": [
    "# Song divided every 5s, only mean features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(song, sr):\n",
    "    data = []\n",
    "    \n",
    "    for part in song:\n",
    "        #s_part = np.array(part)\n",
    "        res = []\n",
    "        union = 0\n",
    "        mfcc = librosa.feature.mfcc(part, sr)\n",
    "        for element in mfcc:\n",
    "            #union = sum(element)\n",
    "            res.append((sum(element)/mfcc.shape[1]))\n",
    "        #res.append((union/mfcc.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        rms = librosa.feature.rms(part, sr)\n",
    "        union = sum(rms[0])\n",
    "        res.append((union/rms.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        chroma_stft = librosa.feature.chroma_stft(part, sr)\n",
    "        for element in chroma_stft:\n",
    "            #union = sum(element)\n",
    "            res.append((sum(element)/chroma_stft.shape[1]))\n",
    "        #res.append((union/chroma_stft.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(part, sr)\n",
    "        union = sum(spectral_bandwidth[0])\n",
    "        res.append((union/spectral_bandwidth.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(part, sr)\n",
    "        for element in spectral_contrast:\n",
    "            #union = sum(element)\n",
    "            res.append((sum(element)/spectral_contrast.shape[1]))\n",
    "        #res.append((union/spectral_contrast.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        spectral_flatness = librosa.feature.spectral_flatness(part)\n",
    "        union = sum(spectral_flatness[0])\n",
    "        res.append((union/spectral_flatness.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(part, sr)\n",
    "        union = sum(spectral_rolloff[0])\n",
    "        res.append((union/spectral_rolloff.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(part, sr)\n",
    "        union = sum(spectral_centroid[0])\n",
    "        res.append((union/spectral_centroid.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        tonnetz = librosa.feature.tonnetz(part, sr)\n",
    "        for element in tonnetz:\n",
    "            #union = sum(element)\n",
    "            res.append((sum(element)/tonnetz.shape[1]))\n",
    "        #res.append((union/tonnetz.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(part, sr)\n",
    "        union = sum(zero_crossing_rate[0])\n",
    "        \n",
    "        res.append((union/zero_crossing_rate.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        tempogram = librosa.feature.tempogram(part, sr)\n",
    "        for element in tempogram:\n",
    "            #union = sum(element)\n",
    "            res.append((sum(element)/tempogram.shape[1]))\n",
    "        #res.append((union/tempogram.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        fourier_tempogram = librosa.feature.fourier_tempogram(part, sr)\n",
    "        for element in fourier_tempogram:\n",
    "            #union = abs(sum(element))\n",
    "            res.append((sum(element).real/fourier_tempogram.shape[1]))\n",
    "        #res.append((union/fourier_tempogram.shape[1]))\n",
    "        \n",
    "        tempo = librosa.beat.tempo(part, sr)\n",
    "        res.append(tempo[0])\n",
    "        \n",
    "        beat_track = librosa.beat.beat_track(part, sr)\n",
    "        res.append(beat_track[0])\n",
    "        \n",
    "        union = 0\n",
    "        plp = librosa.beat.plp(part, sr)\n",
    "        for element in plp:\n",
    "            union += element\n",
    "        res.append((union/plp.shape[0]))\n",
    "        \n",
    "        data.append(res)\n",
    "\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c5e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x,y = songs_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef086a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9b8f3",
   "metadata": {},
   "source": [
    "# Song divided every 5s, only features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_full_song(song, sr):\n",
    "    res = []\n",
    "    \n",
    "    union = song\n",
    "    mfcc = librosa.feature.mfcc(song, sr)\n",
    "    for element in mfcc:\n",
    "        union = np.concatenate((union, element), axis=None)\n",
    "    res.append(union)\n",
    "\n",
    "    union = song\n",
    "    chroma_stft = librosa.feature.chroma_stft(song, sr)\n",
    "    for element in chroma_stft:\n",
    "        union = np.concatenate((union, element), axis=None)\n",
    "    res.append(union)\n",
    "\n",
    "    union = song\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(song, sr)\n",
    "    union = np.concatenate((union, spectral_centroid), axis=None)\n",
    "    res.append(union)\n",
    "\n",
    "    union = song\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(song, sr)\n",
    "    union = np.concatenate((union, zero_crossing_rate), axis=None)\n",
    "    res.append(union)\n",
    "    \n",
    "    return np.array(res)\n",
    "\n",
    "def load_full_song(path):\n",
    "    x , sr = librosa.load(path, mono=True, sr=44100)\n",
    "    song_features = add_features_full_song(x, sr)\n",
    "    song = np.array([song_features])\n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c449ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_songs_array(default = 'music'):\n",
    "    data = []\n",
    "    y = []\n",
    "    for song_path, genre in music_path(default): \n",
    "        for part_song in load_full_song(song_path):\n",
    "            data.append(part_song)\n",
    "            y.append(genre)\n",
    "    return np.array(data), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ed6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x,y = full_songs_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b609cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f95053",
   "metadata": {},
   "source": [
    "# Image song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b45627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def music_path(path, to_predict):\n",
    "    directories = [i for i in listdir(path) if not i.startswith(\".\")]\n",
    "    \n",
    "    if to_predict:\n",
    "        directories.remove('Image')\n",
    "        \n",
    "    for genre in directories:\n",
    "        for song in listdir(f\"{path}/{genre}\"):\n",
    "            if not song.startswith(\".\"):\n",
    "                yield f\"{path}/{genre}/{song}\", genre\n",
    "                \n",
    "def check_folder(path):\n",
    "    path_folder = path.split('/')\n",
    "    if not os.path.isdir(f'{path_folder[0]}/{path_folder[1]}'):\n",
    "        os.mkdir(f'{path_folder[0]}/{path_folder[1]}')\n",
    "        \n",
    "def save_image(song, path):\n",
    "    check_folder(path)\n",
    "    stft = librosa.stft(song)\n",
    "    song_db = librosa.amplitude_to_db(stft)\n",
    "    librosa.display.specshow(song_db)\n",
    "    plt.savefig(f'{path}.png')\n",
    "    plt.close()\n",
    "    \n",
    "def create_image(default = 'music', to_predict=False):\n",
    "    data = []\n",
    "    y = []\n",
    "    for song_path, genre in music_path(default, to_predict):\n",
    "        tree_dir = song_path.split(\"/\")\n",
    "        x , sr = librosa.load(song_path, mono=True, sr=44100)\n",
    "        if to_predict:\n",
    "            save_image(x, f\"one/Image/{tree_dir[-1].replace('.wav','').replace('.mp3','')}\")\n",
    "        else:\n",
    "            save_image(x, f\"music_image/{genre}/{tree_dir[-1].replace('.wav','')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1a7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7debd7d0",
   "metadata": {},
   "source": [
    "## Leemos las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b42caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4213ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img, (img_size, img_size))\n",
    "    return img_resized\n",
    "\n",
    "def img_path(path, to_predict):\n",
    "    directories = [i for i in listdir(path) if not i.startswith(\".\")]\n",
    "    \n",
    "    if to_predict:\n",
    "        directories.remove('Music')\n",
    "    \n",
    "    for genre in directories:\n",
    "        for song_img in listdir(f\"{path}/{genre}\"):\n",
    "            if not song_img.startswith(\".\"):\n",
    "                yield f\"{path}/{genre}/{song_img}\", genre\n",
    "\n",
    "def get_img_data(path = 'music_image', to_predict=False):\n",
    "    data = []\n",
    "    y = []\n",
    "    for img_p, genre in img_path(path, to_predict):\n",
    "        data.append(read_img(img_p))\n",
    "        y.append(genre)\n",
    "    return np.array(data), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1a79af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = get_img_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b2800a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 255, 255, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4828ff",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe9d1f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre = pd.DataFrame(data=y, columns=[\"Genero\"])\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(genre[[\"Genero\"]])\n",
    "genre_ohe = ohe.transform(genre[[\"Genero\"]]).todense()\n",
    "genre_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8463b824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metal</th>\n",
       "      <th>pop</th>\n",
       "      <th>rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     metal  pop  rock\n",
       "0      1.0  0.0   0.0\n",
       "1      1.0  0.0   0.0\n",
       "2      1.0  0.0   0.0\n",
       "3      1.0  0.0   0.0\n",
       "4      1.0  0.0   0.0\n",
       "..     ...  ...   ...\n",
       "145    0.0  0.0   1.0\n",
       "146    0.0  0.0   1.0\n",
       "147    0.0  0.0   1.0\n",
       "148    0.0  0.0   1.0\n",
       "149    0.0  0.0   1.0\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directories = [i for i in listdir(\"music\") if not i.startswith(\".\")]\n",
    "df_ohe = pd.DataFrame(data=genre_ohe, columns=directories)\n",
    "df_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67827e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(x, genre_ohe, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01dcdb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 255, 255, 3), (38, 255, 255, 3), (112, 3), (38, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06270b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[15., 11., 12.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.sum(axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3edfc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d614d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 255, 255, 3), (38, 255, 255, 3), (112, 3), (38, 3))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train / 255\n",
    "X_val = X_val / 255\n",
    "\n",
    "X_train.reshape(-1, img_size, img_size, 1)\n",
    "X_val.reshape(-1, img_size, img_size, 1)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "073f6f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 00:36:56.409973: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-26 00:36:56.410475: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-26 00:36:56.413237: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(128,3,padding='same', activation='relu', input_shape= (img_size, img_size, 3)),\n",
    "    MaxPool2D(),\n",
    "    \n",
    "    Conv2D(256, 3, padding='same', activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    \n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4522d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model = Sequential([\n",
    "    Dense(512, activation=\"relu\", input_shape = (img_size, img_size, 3)),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(3, activation=\"softmax\")\n",
    "])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71a38c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 255, 255, 128)     3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 127, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 127, 127, 256)     295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 63, 63, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 31, 31, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 492032)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               62980224  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 64,459,523\n",
      "Trainable params: 64,459,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73150538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 255, 255, 3), (112, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49b9b128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 00:37:09.787102: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-10-26 00:37:09.790787: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3800020000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 25s 6s/step - loss: 1.7967 - accuracy: 0.3405 - val_loss: 1.0936 - val_accuracy: 0.3947\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.1578 - accuracy: 0.2760 - val_loss: 1.0843 - val_accuracy: 0.3947\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.0945 - accuracy: 0.3510 - val_loss: 1.0869 - val_accuracy: 0.5263\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.0950 - accuracy: 0.3856 - val_loss: 1.0924 - val_accuracy: 0.3158\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 1.0920 - accuracy: 0.3982 - val_loss: 1.0878 - val_accuracy: 0.2895\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.0853 - accuracy: 0.3949 - val_loss: 1.0843 - val_accuracy: 0.3158\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.0753 - accuracy: 0.4062 - val_loss: 1.0658 - val_accuracy: 0.4474\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.0709 - accuracy: 0.4345 - val_loss: 1.0445 - val_accuracy: 0.4474\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 1.0444 - accuracy: 0.5362 - val_loss: 1.0204 - val_accuracy: 0.6316\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.0203 - accuracy: 0.6548 - val_loss: 0.9772 - val_accuracy: 0.7895\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.9802 - accuracy: 0.7131 - val_loss: 0.9476 - val_accuracy: 0.5526\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.9375 - accuracy: 0.6457 - val_loss: 0.8196 - val_accuracy: 0.8158\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.8679 - accuracy: 0.6753 - val_loss: 0.7360 - val_accuracy: 0.7895\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.7701 - accuracy: 0.7045 - val_loss: 0.6587 - val_accuracy: 0.7895\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6686 - accuracy: 0.7705 - val_loss: 0.5719 - val_accuracy: 0.8158\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6639 - accuracy: 0.7548 - val_loss: 0.4937 - val_accuracy: 0.8684\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.6206 - accuracy: 0.7561 - val_loss: 0.4858 - val_accuracy: 0.7895\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.5269 - accuracy: 0.8397 - val_loss: 0.4479 - val_accuracy: 0.8684\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.5115 - accuracy: 0.7937 - val_loss: 0.4760 - val_accuracy: 0.8421\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.5444 - accuracy: 0.7921 - val_loss: 0.4334 - val_accuracy: 0.8684\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.4926 - accuracy: 0.8031 - val_loss: 0.4733 - val_accuracy: 0.8158\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.5417 - accuracy: 0.7332 - val_loss: 0.3866 - val_accuracy: 0.8947\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4352 - accuracy: 0.8537 - val_loss: 0.3681 - val_accuracy: 0.8947\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.4254 - accuracy: 0.8503 - val_loss: 0.3924 - val_accuracy: 0.8684\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4112 - accuracy: 0.8829 - val_loss: 0.3847 - val_accuracy: 0.8421\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.4015 - accuracy: 0.8491 - val_loss: 0.4417 - val_accuracy: 0.8158\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4765 - accuracy: 0.8086 - val_loss: 0.3637 - val_accuracy: 0.8421\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.3686 - accuracy: 0.8658 - val_loss: 0.4849 - val_accuracy: 0.8158\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.4963 - accuracy: 0.7854 - val_loss: 0.3327 - val_accuracy: 0.8684\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.3431 - accuracy: 0.8999 - val_loss: 0.3672 - val_accuracy: 0.8684\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.3033 - accuracy: 0.8906 - val_loss: 0.3023 - val_accuracy: 0.9211\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.2681 - accuracy: 0.9376 - val_loss: 0.3224 - val_accuracy: 0.8684\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.3242 - accuracy: 0.8893 - val_loss: 0.2692 - val_accuracy: 0.9211\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.3109 - accuracy: 0.9085 - val_loss: 0.2752 - val_accuracy: 0.9211\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.2177 - accuracy: 0.9512 - val_loss: 0.3945 - val_accuracy: 0.8421\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.4392 - accuracy: 0.8202 - val_loss: 0.2683 - val_accuracy: 0.9211\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.3157 - accuracy: 0.8940 - val_loss: 0.3221 - val_accuracy: 0.8684\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.3050 - accuracy: 0.8879 - val_loss: 0.3181 - val_accuracy: 0.8684\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.3357 - accuracy: 0.8750 - val_loss: 0.3912 - val_accuracy: 0.8421\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.2957 - accuracy: 0.8875 - val_loss: 0.3347 - val_accuracy: 0.8947\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.2695 - accuracy: 0.8487 - val_loss: 0.4068 - val_accuracy: 0.8684\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.3407 - accuracy: 0.8515 - val_loss: 0.2747 - val_accuracy: 0.8947\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.2636 - accuracy: 0.9043 - val_loss: 0.3907 - val_accuracy: 0.8684\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.3023 - accuracy: 0.8661 - val_loss: 0.3460 - val_accuracy: 0.8947\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.3085 - accuracy: 0.9060 - val_loss: 0.5011 - val_accuracy: 0.7895\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.3461 - accuracy: 0.8253 - val_loss: 0.3487 - val_accuracy: 0.8947\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.2900 - accuracy: 0.9019 - val_loss: 0.3978 - val_accuracy: 0.8684\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.3744 - accuracy: 0.8482 - val_loss: 0.2595 - val_accuracy: 0.8947\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.3565 - accuracy: 0.8683 - val_loss: 0.2849 - val_accuracy: 0.8684\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.2949 - accuracy: 0.8751 - val_loss: 0.3085 - val_accuracy: 0.8684\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.3160 - accuracy: 0.8725 - val_loss: 0.3138 - val_accuracy: 0.8684\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.2797 - accuracy: 0.8957 - val_loss: 0.2452 - val_accuracy: 0.8947\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.2411 - accuracy: 0.9375 - val_loss: 0.2274 - val_accuracy: 0.9211\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.2276 - accuracy: 0.9314 - val_loss: 0.2348 - val_accuracy: 0.9211\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.2292 - accuracy: 0.9241 - val_loss: 0.1996 - val_accuracy: 0.8947\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.2503 - accuracy: 0.9158 - val_loss: 0.2232 - val_accuracy: 0.9211\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.1396 - accuracy: 0.9661 - val_loss: 0.2632 - val_accuracy: 0.8947\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.1969 - accuracy: 0.9458 - val_loss: 0.2331 - val_accuracy: 0.8947\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.2095 - accuracy: 0.9135 - val_loss: 0.1980 - val_accuracy: 0.9211\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.1994 - accuracy: 0.9198 - val_loss: 0.2007 - val_accuracy: 0.8684\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.1668 - accuracy: 0.9405 - val_loss: 0.1960 - val_accuracy: 0.8684\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.1289 - accuracy: 0.9613 - val_loss: 0.1746 - val_accuracy: 0.8947\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.1385 - accuracy: 0.9463 - val_loss: 0.1687 - val_accuracy: 0.9211\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.1223 - accuracy: 0.9841 - val_loss: 0.2223 - val_accuracy: 0.8947\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 20s 5s/step - loss: 0.1814 - accuracy: 0.9292 - val_loss: 0.1912 - val_accuracy: 0.8947\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.1622 - accuracy: 0.9408 - val_loss: 0.2856 - val_accuracy: 0.8684\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.1880 - accuracy: 0.9369 - val_loss: 0.1868 - val_accuracy: 0.9211\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.1521 - accuracy: 0.9726 - val_loss: 0.2397 - val_accuracy: 0.8684\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.1328 - accuracy: 0.9606 - val_loss: 0.1959 - val_accuracy: 0.9211\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.2740 - accuracy: 0.8637 - val_loss: 0.1891 - val_accuracy: 0.9211\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.1621 - accuracy: 0.9388 - val_loss: 0.1910 - val_accuracy: 0.8947\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.1710 - accuracy: 0.9640 - val_loss: 0.2121 - val_accuracy: 0.8947\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.2418 - accuracy: 0.9143 - val_loss: 0.1939 - val_accuracy: 0.9211\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.1293 - accuracy: 0.9887 - val_loss: 0.2309 - val_accuracy: 0.8947\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.1669 - accuracy: 0.9618 - val_loss: 0.2292 - val_accuracy: 0.8947\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.1127 - accuracy: 0.9613 - val_loss: 0.1742 - val_accuracy: 0.9211\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.1053 - accuracy: 0.9824 - val_loss: 0.1826 - val_accuracy: 0.8684\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0785 - accuracy: 0.9799 - val_loss: 0.1806 - val_accuracy: 0.8421\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0809 - accuracy: 0.9638 - val_loss: 0.1693 - val_accuracy: 0.9211\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.0669 - accuracy: 0.9814 - val_loss: 0.1779 - val_accuracy: 0.8421\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0623 - accuracy: 0.9943 - val_loss: 0.1730 - val_accuracy: 0.8684\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0688 - accuracy: 0.9705 - val_loss: 0.1819 - val_accuracy: 0.8421\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0480 - accuracy: 0.9908 - val_loss: 0.1693 - val_accuracy: 0.9211\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0711 - accuracy: 0.9762 - val_loss: 0.1685 - val_accuracy: 0.9474\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0548 - accuracy: 0.9912 - val_loss: 0.1989 - val_accuracy: 0.8684\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0500 - accuracy: 0.9824 - val_loss: 0.1799 - val_accuracy: 0.8947\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0534 - accuracy: 0.9824 - val_loss: 0.2186 - val_accuracy: 0.8947\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.0605 - accuracy: 0.9912 - val_loss: 0.1681 - val_accuracy: 0.8947\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0375 - accuracy: 0.9912 - val_loss: 0.2000 - val_accuracy: 0.8684\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0541 - accuracy: 0.9856 - val_loss: 0.1810 - val_accuracy: 0.8947\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0441 - accuracy: 0.9830 - val_loss: 0.1977 - val_accuracy: 0.8684\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.0479 - accuracy: 0.9850 - val_loss: 0.1969 - val_accuracy: 0.8947\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 0.1712 - val_accuracy: 0.8947\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.8684\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.8947\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0366 - accuracy: 0.9943 - val_loss: 0.1896 - val_accuracy: 0.8947\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.8947\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.8684\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9211\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0365 - accuracy: 0.9856 - val_loss: 0.1892 - val_accuracy: 0.9211\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train,\n",
    "         validation_data=(X_val, \n",
    "                          y_val),\n",
    "         epochs=100,\n",
    "         verbose=1,\n",
    "         batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17e7f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model/image_features.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf14633",
   "metadata": {},
   "source": [
    "# Predict data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d118034e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 01:24:52.526078: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-26 01:24:52.526568: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-26 01:24:52.528987: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = models.load_model('saved_model/image_features.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cb948e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_image('one', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d59c1c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one/Image/Heart - Barracuda.png\n"
     ]
    }
   ],
   "source": [
    "x,y = get_img_data('one', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42fc7460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 255, 255, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0537749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f26e2dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe912ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metal -> 0.0\n",
      "pop -> 0.0\n",
      "rock -> 100.0\n"
     ]
    }
   ],
   "source": [
    "directories = [i for i in listdir(\"music\") if not i.startswith(\".\")]\n",
    "res = {}\n",
    "for d in directories:\n",
    "    res[d] = 0\n",
    "\n",
    "for part_song in range(len(y_pred)):\n",
    "    for percent_predict in range(len(y_pred[part_song])):\n",
    "        res[directories[percent_predict]] += y_pred[part_song][percent_predict]\n",
    "\n",
    "for i in res.items():\n",
    "    print(f\"{i[0]} -> {(i[1]/x.shape[0])*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5849b90c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

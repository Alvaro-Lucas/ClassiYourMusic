{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcef3f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: CPU random generator seem to be failing, disable hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import time\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import youtube_dl\n",
    "import librosa\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from __future__ import unicode_literals\n",
    "from os import path, listdir \n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903c9e4",
   "metadata": {},
   "source": [
    "# Song divided every 5s concatenate with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e1cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def music_path(path):\n",
    "    directories = [i for i in listdir(path) if not i.startswith(\".\")]\n",
    "    for genre in directories:\n",
    "        for song in listdir(f\"{path}/{genre}\"):\n",
    "            if not song.startswith(\".\"):\n",
    "                yield f\"{path}/{genre}/{song}\", genre\n",
    "                \n",
    "def add_features(song, sr):\n",
    "    res = []\n",
    "    for part in song:\n",
    "        union = part\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(part, sr)\n",
    "        print(mfcc.shape)\n",
    "        for element in mfcc:\n",
    "            union = np.concatenate((union, element), axis=None)\n",
    "        \n",
    "        chroma_stft = librosa.feature.chroma_stft(part, sr)\n",
    "        for element in chroma_stft:\n",
    "            union = np.concatenate((union, element), axis=None)\n",
    "        \n",
    "        spectral_centroid = librosa.feature.spectral_centroid(part, sr)\n",
    "        union = np.concatenate((union, spectral_centroid), axis=None)\n",
    "        \n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(part, sr)\n",
    "        union = np.concatenate((union, zero_crossing_rate), axis=None)\n",
    "        res.append(union)\n",
    "    return np.array(res)\n",
    "        \n",
    "def split_song(song, sr, seconds = 5):\n",
    "    res = []\n",
    "    for i in range(1, len(song)//(sr*seconds)):\n",
    "        res.append(song[(i-1)*sr*seconds : i*sr*seconds])\n",
    "    return np.array(res)\n",
    "                \n",
    "def load_song(path):\n",
    "    x , sr = librosa.load(path, mono=True, sr=44100)\n",
    "    splited_song = split_song(x,sr,5)\n",
    "    for song in add_features(splited_song, sr):\n",
    "        yield song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490bc767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def songs_array(default = 'music'):\n",
    "    data = []\n",
    "    y = []\n",
    "    for song_path, genre in music_path(default): \n",
    "        for part_song in load_song(song_path):\n",
    "            data.append(part_song)\n",
    "            y.append(genre)\n",
    "    return np.array(data), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce68cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x,y = songs_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a68961",
   "metadata": {},
   "source": [
    "# Song divided every 5s, only mean features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(song, sr):\n",
    "    data = []\n",
    "    \n",
    "    for part in song:\n",
    "        #s_part = np.array(part)\n",
    "        res = []\n",
    "        union = 0\n",
    "        mfcc = librosa.feature.mfcc(part, sr)\n",
    "        for element in mfcc:\n",
    "            #union = sum(element)\n",
    "            res.append((sum(element)/mfcc.shape[1]))\n",
    "        #res.append((union/mfcc.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        rms = librosa.feature.rms(part, sr)\n",
    "        union = sum(rms[0])\n",
    "        res.append((union/rms.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        chroma_stft = librosa.feature.chroma_stft(part, sr)\n",
    "        for element in chroma_stft:\n",
    "            #union = sum(element)\n",
    "            res.append((sum(element)/chroma_stft.shape[1]))\n",
    "        #res.append((union/chroma_stft.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(part, sr)\n",
    "        union = sum(spectral_bandwidth[0])\n",
    "        res.append((union/spectral_bandwidth.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(part, sr)\n",
    "        for element in spectral_contrast:\n",
    "            #union = sum(element)\n",
    "            res.append((sum(element)/spectral_contrast.shape[1]))\n",
    "        #res.append((union/spectral_contrast.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        spectral_flatness = librosa.feature.spectral_flatness(part)\n",
    "        union = sum(spectral_flatness[0])\n",
    "        res.append((union/spectral_flatness.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(part, sr)\n",
    "        union = sum(spectral_rolloff[0])\n",
    "        res.append((union/spectral_rolloff.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(part, sr)\n",
    "        union = sum(spectral_centroid[0])\n",
    "        res.append((union/spectral_centroid.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        tonnetz = librosa.feature.tonnetz(part, sr)\n",
    "        for element in tonnetz:\n",
    "            #union = sum(element)\n",
    "            res.append((sum(element)/tonnetz.shape[1]))\n",
    "        #res.append((union/tonnetz.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(part, sr)\n",
    "        union = sum(zero_crossing_rate[0])\n",
    "        \n",
    "        res.append((union/zero_crossing_rate.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        tempogram = librosa.feature.tempogram(part, sr)\n",
    "        for element in tempogram:\n",
    "            #union = sum(element)\n",
    "            res.append((sum(element)/tempogram.shape[1]))\n",
    "        #res.append((union/tempogram.shape[1]))\n",
    "        \n",
    "        union = 0\n",
    "        fourier_tempogram = librosa.feature.fourier_tempogram(part, sr)\n",
    "        for element in fourier_tempogram:\n",
    "            #union = abs(sum(element))\n",
    "            res.append((sum(element).real/fourier_tempogram.shape[1]))\n",
    "        #res.append((union/fourier_tempogram.shape[1]))\n",
    "        \n",
    "        tempo = librosa.beat.tempo(part, sr)\n",
    "        res.append(tempo[0])\n",
    "        \n",
    "        beat_track = librosa.beat.beat_track(part, sr)\n",
    "        res.append(beat_track[0])\n",
    "        \n",
    "        union = 0\n",
    "        plp = librosa.beat.plp(part, sr)\n",
    "        for element in plp:\n",
    "            union += element\n",
    "        res.append((union/plp.shape[0]))\n",
    "        \n",
    "        data.append(res)\n",
    "\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c5e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x,y = songs_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef086a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9b8f3",
   "metadata": {},
   "source": [
    "# Song divided every 5s, only features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_full_song(song, sr):\n",
    "    res = []\n",
    "    \n",
    "    union = song\n",
    "    mfcc = librosa.feature.mfcc(song, sr)\n",
    "    for element in mfcc:\n",
    "        union = np.concatenate((union, element), axis=None)\n",
    "    res.append(union)\n",
    "\n",
    "    union = song\n",
    "    chroma_stft = librosa.feature.chroma_stft(song, sr)\n",
    "    for element in chroma_stft:\n",
    "        union = np.concatenate((union, element), axis=None)\n",
    "    res.append(union)\n",
    "\n",
    "    union = song\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(song, sr)\n",
    "    union = np.concatenate((union, spectral_centroid), axis=None)\n",
    "    res.append(union)\n",
    "\n",
    "    union = song\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(song, sr)\n",
    "    union = np.concatenate((union, zero_crossing_rate), axis=None)\n",
    "    res.append(union)\n",
    "    \n",
    "    return np.array(res)\n",
    "\n",
    "def load_full_song(path):\n",
    "    x , sr = librosa.load(path, mono=True, sr=44100)\n",
    "    song_features = add_features_full_song(x, sr)\n",
    "    song = np.array([song_features])\n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c449ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_songs_array(default = 'music'):\n",
    "    data = []\n",
    "    y = []\n",
    "    for song_path, genre in music_path(default): \n",
    "        for part_song in load_full_song(song_path):\n",
    "            data.append(part_song)\n",
    "            y.append(genre)\n",
    "    return np.array(data), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ed6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x,y = full_songs_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b609cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f95053",
   "metadata": {},
   "source": [
    "# Image song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b45627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def music_path(path, to_predict):\n",
    "    directories = [i for i in listdir(path) if not i.startswith(\".\")]\n",
    "    \n",
    "    if to_predict:\n",
    "        directories.remove('Image')\n",
    "        \n",
    "    for genre in directories:\n",
    "        for song in listdir(f\"{path}/{genre}\"):\n",
    "            if not song.startswith(\".\"):\n",
    "                yield f\"{path}/{genre}/{song}\", genre\n",
    "                \n",
    "def check_folder(path):\n",
    "    path_folder = path.split('/')\n",
    "    if not os.path.isdir(f'{path_folder[0]}/{path_folder[1]}'):\n",
    "        os.mkdir(f'{path_folder[0]}/{path_folder[1]}')\n",
    "        \n",
    "def save_image(song, path):\n",
    "    check_folder(path)\n",
    "    stft = librosa.stft(song)\n",
    "    song_db = librosa.amplitude_to_db(stft)\n",
    "    librosa.display.specshow(song_db)\n",
    "    plt.savefig(f'{path}.png')\n",
    "    plt.close()\n",
    "    \n",
    "def create_image(default = 'music', to_predict=False):\n",
    "    data = []\n",
    "    y = []\n",
    "    for song_path, genre in music_path(default, to_predict):\n",
    "        tree_dir = song_path.split(\"/\")\n",
    "        x , sr = librosa.load(song_path, mono=True, sr=44100)\n",
    "        if to_predict:\n",
    "            save_image(x, f\"one/Image/{tree_dir[-1].replace('.wav','').replace('.mp3','')}\")\n",
    "        else:\n",
    "            save_image(x, f\"music_image/{genre}/{tree_dir[-1].replace('.wav','')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1a7fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7debd7d0",
   "metadata": {},
   "source": [
    "## Leemos las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b42caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4213ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img, (img_size, img_size))\n",
    "    return img_resized\n",
    "\n",
    "def img_path(path, to_predict):\n",
    "    directories = [i for i in listdir(path) if not i.startswith(\".\")]\n",
    "    \n",
    "    if to_predict:\n",
    "        directories.remove('Music')\n",
    "    \n",
    "    for genre in directories:\n",
    "        for song_img in listdir(f\"{path}/{genre}\"):\n",
    "            if not song_img.startswith(\".\"):\n",
    "                yield f\"{path}/{genre}/{song_img}\", genre\n",
    "\n",
    "def get_img_data(path = 'music_image', to_predict=False):\n",
    "    data = []\n",
    "    y = []\n",
    "    for img_p, genre in img_path(path, to_predict):\n",
    "        data.append(read_img(img_p))\n",
    "        y.append(genre)\n",
    "    return np.array(data), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a79af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = get_img_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b2800a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(599, 255, 255, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4828ff",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe9d1f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = pd.DataFrame(data=y, columns=[\"Genero\"])\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(genre[[\"Genero\"]])\n",
    "genre_ohe = ohe.transform(genre[[\"Genero\"]]).todense()\n",
    "#genre_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8463b824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blues</th>\n",
       "      <th>classical</th>\n",
       "      <th>country</th>\n",
       "      <th>disco</th>\n",
       "      <th>hiphop</th>\n",
       "      <th>jazz</th>\n",
       "      <th>metal</th>\n",
       "      <th>pop</th>\n",
       "      <th>reggae</th>\n",
       "      <th>rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>599 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     blues  classical  country  disco  hiphop  jazz  metal  pop  reggae  rock\n",
       "0      0.0        0.0      0.0    0.0     1.0   0.0    0.0  0.0     0.0   0.0\n",
       "1      0.0        0.0      0.0    0.0     1.0   0.0    0.0  0.0     0.0   0.0\n",
       "2      0.0        0.0      0.0    0.0     1.0   0.0    0.0  0.0     0.0   0.0\n",
       "3      0.0        0.0      0.0    0.0     1.0   0.0    0.0  0.0     0.0   0.0\n",
       "4      0.0        0.0      0.0    0.0     1.0   0.0    0.0  0.0     0.0   0.0\n",
       "..     ...        ...      ...    ...     ...   ...    ...  ...     ...   ...\n",
       "594    0.0        0.0      0.0    0.0     0.0   0.0    0.0  0.0     1.0   0.0\n",
       "595    0.0        0.0      0.0    0.0     0.0   0.0    0.0  0.0     1.0   0.0\n",
       "596    0.0        0.0      0.0    0.0     0.0   0.0    0.0  0.0     1.0   0.0\n",
       "597    0.0        0.0      0.0    0.0     0.0   0.0    0.0  0.0     1.0   0.0\n",
       "598    0.0        0.0      0.0    0.0     0.0   0.0    0.0  0.0     1.0   0.0\n",
       "\n",
       "[599 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directories = sorted([i for i in listdir(\"music_image\") if not i.startswith(\".\")])\n",
    "df_ohe = pd.DataFrame(data=genre_ohe, columns=directories)\n",
    "df_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67827e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(x, genre_ohe, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01dcdb64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((419, 255, 255, 3), (180, 255, 255, 3), (419, 10), (180, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9583fd79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.sum(axis=-2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "001978c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[16., 28., 12., 15., 17., 18., 19., 17., 22., 16.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.sum(axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3edfc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d614d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((419, 255, 255, 3), (180, 255, 255, 3), (419, 10), (180, 10))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train / 255\n",
    "X_val = X_val / 255\n",
    "\n",
    "X_train.reshape(-1, img_size, img_size, 1)\n",
    "X_val.reshape(-1, img_size, img_size, 1)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "073f6f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 23:29:19.253659: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-26 23:29:19.255853: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-26 23:29:19.259061: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(128,3,padding='same', activation='relu', input_shape= (img_size, img_size, 3)),\n",
    "    MaxPool2D(),\n",
    "    \n",
    "    Conv2D(256, 3, padding='same', activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    \n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    \n",
    "    Conv2D(1024, 3, padding='same', activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4522d82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = Sequential([\\n    Dense(512, activation=\"relu\", input_shape = (img_size, img_size, 3)),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(1_000, activation=\"relu\"),\\n    Dense(3, activation=\"softmax\")\\n])'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = Sequential([\n",
    "    Dense(512, activation=\"relu\", input_shape = (img_size, img_size, 3)),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(1_000, activation=\"relu\"),\n",
    "    Dense(3, activation=\"softmax\")\n",
    "])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71a38c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 255, 255, 128)     3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 127, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 127, 127, 256)     295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 63, 63, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 31, 31, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 31, 31, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 1024)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 15, 1024)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 230400)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               29491328  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 35,691,146\n",
      "Trainable params: 35,691,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73150538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((419, 255, 255, 3), (419, 10))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49b9b128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 23:29:25.251569: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-10-26 23:29:25.254371: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3800020000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "14/14 [==============================] - 84s 6s/step - loss: 2.3588 - accuracy: 0.1181 - val_loss: 2.3112 - val_accuracy: 0.1111\n",
      "Epoch 2/500\n",
      "14/14 [==============================] - 81s 6s/step - loss: 2.2865 - accuracy: 0.1431 - val_loss: 2.2506 - val_accuracy: 0.1444\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - 82s 6s/step - loss: 2.2460 - accuracy: 0.1627 - val_loss: 2.0333 - val_accuracy: 0.2278\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - 82s 6s/step - loss: 2.1455 - accuracy: 0.1616 - val_loss: 2.0199 - val_accuracy: 0.2333\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - 82s 6s/step - loss: 2.0268 - accuracy: 0.2393 - val_loss: 1.9631 - val_accuracy: 0.3111\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - 84s 6s/step - loss: 2.0163 - accuracy: 0.2444 - val_loss: 1.9146 - val_accuracy: 0.2222\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - 81s 6s/step - loss: 1.8586 - accuracy: 0.3005 - val_loss: 1.7917 - val_accuracy: 0.3389\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - 80s 6s/step - loss: 1.8167 - accuracy: 0.3256 - val_loss: 1.7200 - val_accuracy: 0.2833\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 1.7376 - accuracy: 0.3741 - val_loss: 1.6946 - val_accuracy: 0.2778\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 1.7223 - accuracy: 0.3542 - val_loss: 1.6161 - val_accuracy: 0.3778\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - 83s 6s/step - loss: 1.6490 - accuracy: 0.3939 - val_loss: 1.4856 - val_accuracy: 0.4389\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 1.5034 - accuracy: 0.4506 - val_loss: 1.4631 - val_accuracy: 0.4111\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 1.4602 - accuracy: 0.4828 - val_loss: 1.4447 - val_accuracy: 0.4444\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - 81s 6s/step - loss: 1.4035 - accuracy: 0.4782 - val_loss: 1.4103 - val_accuracy: 0.4556\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 1.4036 - accuracy: 0.4971 - val_loss: 1.4215 - val_accuracy: 0.4444\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - 80s 6s/step - loss: 1.3668 - accuracy: 0.5379 - val_loss: 1.4171 - val_accuracy: 0.4389\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - 82s 6s/step - loss: 1.3517 - accuracy: 0.4863 - val_loss: 1.4944 - val_accuracy: 0.4833\n",
      "Epoch 18/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 1.3937 - accuracy: 0.5039 - val_loss: 1.4779 - val_accuracy: 0.4611\n",
      "Epoch 19/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 1.4088 - accuracy: 0.5145 - val_loss: 1.4332 - val_accuracy: 0.4833\n",
      "Epoch 20/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 1.1949 - accuracy: 0.5779 - val_loss: 1.3647 - val_accuracy: 0.4944\n",
      "Epoch 21/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 1.2045 - accuracy: 0.5988 - val_loss: 1.3185 - val_accuracy: 0.5056\n",
      "Epoch 22/500\n",
      "14/14 [==============================] - 80s 6s/step - loss: 1.2711 - accuracy: 0.5636 - val_loss: 1.3853 - val_accuracy: 0.4722\n",
      "Epoch 23/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 1.2085 - accuracy: 0.5780 - val_loss: 1.3919 - val_accuracy: 0.4500\n",
      "Epoch 24/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 1.1954 - accuracy: 0.5695 - val_loss: 1.3955 - val_accuracy: 0.4611\n",
      "Epoch 25/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 1.0804 - accuracy: 0.6388 - val_loss: 1.2895 - val_accuracy: 0.5111\n",
      "Epoch 26/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 1.1212 - accuracy: 0.6193 - val_loss: 1.3100 - val_accuracy: 0.5111\n",
      "Epoch 27/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 1.0553 - accuracy: 0.6323 - val_loss: 1.3765 - val_accuracy: 0.4778\n",
      "Epoch 28/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 1.0444 - accuracy: 0.6494 - val_loss: 1.2735 - val_accuracy: 0.5056\n",
      "Epoch 29/500\n",
      "14/14 [==============================] - 80s 6s/step - loss: 0.9788 - accuracy: 0.6490 - val_loss: 1.3919 - val_accuracy: 0.5222\n",
      "Epoch 30/500\n",
      "14/14 [==============================] - 82s 6s/step - loss: 1.0170 - accuracy: 0.6550 - val_loss: 1.3179 - val_accuracy: 0.5111\n",
      "Epoch 31/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.8936 - accuracy: 0.6712 - val_loss: 1.2723 - val_accuracy: 0.5222\n",
      "Epoch 32/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.9330 - accuracy: 0.6476 - val_loss: 1.2887 - val_accuracy: 0.5389\n",
      "Epoch 33/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.8721 - accuracy: 0.7048 - val_loss: 1.5604 - val_accuracy: 0.5222\n",
      "Epoch 34/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.9972 - accuracy: 0.6521 - val_loss: 1.5619 - val_accuracy: 0.4722\n",
      "Epoch 35/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.9756 - accuracy: 0.6435 - val_loss: 1.2619 - val_accuracy: 0.5278\n",
      "Epoch 36/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.8614 - accuracy: 0.6929 - val_loss: 1.7232 - val_accuracy: 0.4833\n",
      "Epoch 37/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 1.0520 - accuracy: 0.6345 - val_loss: 1.3366 - val_accuracy: 0.5278\n",
      "Epoch 38/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.7726 - accuracy: 0.7619 - val_loss: 1.3601 - val_accuracy: 0.5556\n",
      "Epoch 39/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.8043 - accuracy: 0.6900 - val_loss: 1.3604 - val_accuracy: 0.5222\n",
      "Epoch 40/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.7376 - accuracy: 0.7350 - val_loss: 1.3656 - val_accuracy: 0.5444\n",
      "Epoch 41/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.7077 - accuracy: 0.7509 - val_loss: 1.4873 - val_accuracy: 0.5278\n",
      "Epoch 42/500\n",
      "14/14 [==============================] - 86s 6s/step - loss: 0.7067 - accuracy: 0.7295 - val_loss: 1.5016 - val_accuracy: 0.5444\n",
      "Epoch 43/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.6799 - accuracy: 0.7485 - val_loss: 1.3491 - val_accuracy: 0.5556\n",
      "Epoch 44/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.6642 - accuracy: 0.7523 - val_loss: 1.3123 - val_accuracy: 0.5500\n",
      "Epoch 45/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.5659 - accuracy: 0.8123 - val_loss: 1.5713 - val_accuracy: 0.5278\n",
      "Epoch 46/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.6338 - accuracy: 0.7897 - val_loss: 1.5178 - val_accuracy: 0.5444\n",
      "Epoch 47/500\n",
      "14/14 [==============================] - 80s 6s/step - loss: 0.6586 - accuracy: 0.7743 - val_loss: 1.6834 - val_accuracy: 0.5278\n",
      "Epoch 48/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.7371 - accuracy: 0.7462 - val_loss: 1.3737 - val_accuracy: 0.5389\n",
      "Epoch 49/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.6882 - accuracy: 0.7760 - val_loss: 1.3771 - val_accuracy: 0.5500\n",
      "Epoch 50/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.5277 - accuracy: 0.7994 - val_loss: 1.5871 - val_accuracy: 0.5389\n",
      "Epoch 51/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.6069 - accuracy: 0.7744 - val_loss: 1.4422 - val_accuracy: 0.5389\n",
      "Epoch 52/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.5768 - accuracy: 0.7810 - val_loss: 1.5169 - val_accuracy: 0.5222\n",
      "Epoch 53/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.5260 - accuracy: 0.8039 - val_loss: 1.4077 - val_accuracy: 0.5611\n",
      "Epoch 54/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.4868 - accuracy: 0.8483 - val_loss: 1.6902 - val_accuracy: 0.5333\n",
      "Epoch 55/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.5636 - accuracy: 0.8209 - val_loss: 1.6036 - val_accuracy: 0.5278\n",
      "Epoch 56/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.5703 - accuracy: 0.7721 - val_loss: 1.5999 - val_accuracy: 0.5333\n",
      "Epoch 57/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.6620 - accuracy: 0.7785 - val_loss: 1.4357 - val_accuracy: 0.5722\n",
      "Epoch 58/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.3973 - accuracy: 0.8762 - val_loss: 1.5362 - val_accuracy: 0.5389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.4701 - accuracy: 0.8232 - val_loss: 1.5507 - val_accuracy: 0.5944\n",
      "Epoch 60/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.4260 - accuracy: 0.8368 - val_loss: 1.6307 - val_accuracy: 0.5722\n",
      "Epoch 61/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.3867 - accuracy: 0.8707 - val_loss: 1.6991 - val_accuracy: 0.5444\n",
      "Epoch 62/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.3809 - accuracy: 0.8597 - val_loss: 1.5815 - val_accuracy: 0.5889\n",
      "Epoch 63/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.3530 - accuracy: 0.8868 - val_loss: 1.6691 - val_accuracy: 0.6000\n",
      "Epoch 64/500\n",
      "14/14 [==============================] - 80s 6s/step - loss: 0.3031 - accuracy: 0.9036 - val_loss: 1.6421 - val_accuracy: 0.5833\n",
      "Epoch 65/500\n",
      "14/14 [==============================] - 80s 6s/step - loss: 0.2747 - accuracy: 0.9018 - val_loss: 1.8590 - val_accuracy: 0.5722\n",
      "Epoch 66/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.3122 - accuracy: 0.8738 - val_loss: 1.9486 - val_accuracy: 0.5722\n",
      "Epoch 67/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.2647 - accuracy: 0.9007 - val_loss: 1.8938 - val_accuracy: 0.5889\n",
      "Epoch 68/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.3100 - accuracy: 0.9074 - val_loss: 1.9096 - val_accuracy: 0.5667\n",
      "Epoch 69/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.2701 - accuracy: 0.8895 - val_loss: 1.8214 - val_accuracy: 0.5778\n",
      "Epoch 70/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.1952 - accuracy: 0.9528 - val_loss: 2.1507 - val_accuracy: 0.5722\n",
      "Epoch 71/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.2926 - accuracy: 0.9008 - val_loss: 1.7476 - val_accuracy: 0.5778\n",
      "Epoch 72/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.2502 - accuracy: 0.9233 - val_loss: 1.9981 - val_accuracy: 0.5778\n",
      "Epoch 73/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.2024 - accuracy: 0.9245 - val_loss: 2.1045 - val_accuracy: 0.5722\n",
      "Epoch 74/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.1708 - accuracy: 0.9607 - val_loss: 1.9483 - val_accuracy: 0.5611\n",
      "Epoch 75/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.4044 - accuracy: 0.8654 - val_loss: 2.1128 - val_accuracy: 0.5222\n",
      "Epoch 76/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.7703 - accuracy: 0.7900 - val_loss: 1.8152 - val_accuracy: 0.5056\n",
      "Epoch 77/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.6191 - accuracy: 0.7625 - val_loss: 1.6326 - val_accuracy: 0.5444\n",
      "Epoch 78/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.3853 - accuracy: 0.8539 - val_loss: 1.6325 - val_accuracy: 0.5889\n",
      "Epoch 79/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.1626 - accuracy: 0.9569 - val_loss: 1.8832 - val_accuracy: 0.5667\n",
      "Epoch 80/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.1391 - accuracy: 0.9666 - val_loss: 1.9220 - val_accuracy: 0.5889\n",
      "Epoch 81/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.1057 - accuracy: 0.9732 - val_loss: 1.9458 - val_accuracy: 0.6056\n",
      "Epoch 82/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.1182 - accuracy: 0.9671 - val_loss: 2.0277 - val_accuracy: 0.5722\n",
      "Epoch 83/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.0986 - accuracy: 0.9802 - val_loss: 2.1157 - val_accuracy: 0.5778\n",
      "Epoch 84/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.0937 - accuracy: 0.9661 - val_loss: 2.1550 - val_accuracy: 0.5611\n",
      "Epoch 85/500\n",
      "14/14 [==============================] - 81s 6s/step - loss: 0.0858 - accuracy: 0.9864 - val_loss: 2.2668 - val_accuracy: 0.5722\n",
      "Epoch 86/500\n",
      "14/14 [==============================] - 81s 6s/step - loss: 0.0520 - accuracy: 0.9918 - val_loss: 2.3204 - val_accuracy: 0.5667\n",
      "Epoch 87/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.0617 - accuracy: 0.9810 - val_loss: 2.3254 - val_accuracy: 0.5889\n",
      "Epoch 88/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.0374 - accuracy: 0.9986 - val_loss: 2.5923 - val_accuracy: 0.5667\n",
      "Epoch 89/500\n",
      "14/14 [==============================] - 80s 6s/step - loss: 0.1535 - accuracy: 0.9464 - val_loss: 2.6100 - val_accuracy: 0.5722\n",
      "Epoch 90/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.3702 - accuracy: 0.8840 - val_loss: 2.2888 - val_accuracy: 0.5667\n",
      "Epoch 91/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.1749 - accuracy: 0.9066 - val_loss: 2.2825 - val_accuracy: 0.5556\n",
      "Epoch 92/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.1516 - accuracy: 0.9512 - val_loss: 2.0501 - val_accuracy: 0.6000\n",
      "Epoch 93/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.0632 - accuracy: 0.9921 - val_loss: 2.2499 - val_accuracy: 0.5889\n",
      "Epoch 94/500\n",
      "14/14 [==============================] - 82s 6s/step - loss: 0.0399 - accuracy: 0.9968 - val_loss: 2.3374 - val_accuracy: 0.5944\n",
      "Epoch 95/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 2.4772 - val_accuracy: 0.5611\n",
      "Epoch 96/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.0782 - accuracy: 0.9647 - val_loss: 2.5821 - val_accuracy: 0.5556\n",
      "Epoch 97/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.0858 - accuracy: 0.9751 - val_loss: 2.4272 - val_accuracy: 0.5778\n",
      "Epoch 98/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.0486 - accuracy: 0.9812 - val_loss: 2.3526 - val_accuracy: 0.6056\n",
      "Epoch 99/500\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.0423 - accuracy: 0.9944 - val_loss: 2.4821 - val_accuracy: 0.5722\n",
      "Epoch 100/500\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.0249 - accuracy: 0.9992 - val_loss: 2.5208 - val_accuracy: 0.6000\n",
      "Epoch 101/500\n",
      " 1/14 [=>............................] - ETA: 1:10 - loss: 0.0124 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14015/2073422628.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(X_train, \n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m          validation_data=(X_val, \n\u001b[1;32m      4\u001b[0m                           y_val),\n\u001b[1;32m      5\u001b[0m          \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/end/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/end/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/end/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/end/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/end/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/end/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/end/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train,\n",
    "         validation_data=(X_val, \n",
    "                          y_val),\n",
    "         epochs=500,\n",
    "         verbose=1,\n",
    "         batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17e7f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('saved_model/test_full_bad.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf14633",
   "metadata": {},
   "source": [
    "# Predict data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d118034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models.load_model('saved_model/test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb948e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_image('one', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d59c1c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = get_img_data('one', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42fc7460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 255, 255, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0537749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f26e2dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe912ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiphop -> 0.0\n",
      "classical -> 0.0\n",
      "blues -> 0.0\n",
      "metal -> 0.0\n",
      "jazz -> 0.0\n",
      "country -> 100.0\n",
      "pop -> 0.0\n",
      "rock -> 0.0\n",
      "disco -> 0.0\n",
      "reggae -> 0.0\n"
     ]
    }
   ],
   "source": [
    "directories = [i for i in listdir(\"music_image\") if not i.startswith(\".\")]\n",
    "res = {}\n",
    "for d in directories:\n",
    "    res[d] = 0\n",
    "\n",
    "for part_song in range(len(y_pred)):\n",
    "    for percent_predict in range(len(y_pred[part_song])):\n",
    "        res[directories[percent_predict]] += y_pred[part_song][percent_predict]\n",
    "\n",
    "for i in res.items():\n",
    "    print(f\"{i[0]} -> {(i[1]/x.shape[0])*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5849b90c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
